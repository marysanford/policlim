{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ff3ncbgcjzSe"
      },
      "outputs": [],
      "source": [
        "!pip install simpletransformers transformers==4.40.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the required packages\n",
        "\n",
        "# Dataframes\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "# Regular expressions\n",
        "import re\n",
        "\n",
        "# Unidecoder\n",
        "import unicodedata\n",
        "\n",
        "# Timestamp / time measurment\n",
        "import time\n",
        "\n",
        "# for train/test data preparation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Label encode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Model performance scores\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Simpletransformers classifier\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
        "\n",
        "# PyTorch: enable GPU access\n",
        "import torch\n",
        "\n",
        "# For logging and wandb\n",
        "import logging\n",
        "import wandb\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "6ph_4QY2j0WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# required functions\n",
        "def f1_class(labels, preds):\n",
        "    return f1_score(labels, preds, average='binary')\n",
        "def precision(labels, preds):\n",
        "    return precision_score(labels, preds, average='binary')\n",
        "def recall(labels, preds):\n",
        "    return recall_score(labels, preds, average='binary')\n"
      ],
      "metadata": {
        "id": "LwsR9o7Oj8XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/your_working_directory"
      ],
      "metadata": {
        "id": "v-ixe1GXj3nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## load training data"
      ],
      "metadata": {
        "id": "j0uGrOgMkA8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dat = pd.read_csv('training_data.csv')\n",
        "\n",
        "dat['final_climate']=dat['final_climate'].astype(int)"
      ],
      "metadata": {
        "id": "Ast5mXhVkCGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set qs_id as index\n",
        "dat.set_index(\"qs_new\", drop = False, inplace = True, verify_integrity = True)"
      ],
      "metadata": {
        "id": "b-PXixxbkHX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make numeric labels\n",
        "dat[\"label\"] = dat[\"final_climate\"].astype(\"category\").cat.codes\n",
        "dat[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "53i7MxSZldxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make language-class stratification variable\n",
        "# from https://stackoverflow.com/a/62918682\n",
        "dat[\"strata_\"] = dat.set_index(['language','label']).index.factorize()[0]\n"
      ],
      "metadata": {
        "id": "65bpheTtkUdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## make data splits"
      ],
      "metadata": {
        "id": "y8RXtORIkYRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#  train/test split\n",
        "train_ids, test_ids = train_test_split(dat.index.values, test_size = .25, stratify = dat.strata_.values)\n",
        "train_ids, val_ids = train_test_split(train_ids, test_size = .3, stratify = dat.loc[train_ids].strata_.values)\n",
        "\n",
        "print(len(train_ids), \"training samples\")\n",
        "print(len(test_ids), \"test samples\")\n",
        "print(len(val_ids), \"val samples\")\n"
      ],
      "metadata": {
        "id": "qxCupoN4kSxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # create train, val, test dfs\n",
        "train_df = pd.DataFrame(zip(train_ids,dat.loc[train_ids]['original_text'].values,dat.loc[train_ids]['label'].values),columns=['qs_new','text','labels'])\n",
        "test_df = pd.DataFrame(zip(test_ids,dat.loc[test_ids]['original_text'].values,dat.loc[test_ids]['label'].values),columns=['qs_new','text','labels'])\n",
        "val_df = pd.DataFrame(zip(val_ids,dat.loc[val_ids]['original_text'].values,dat.loc[val_ids]['label'].values),columns=['qs_new','text','labels'])\n"
      ],
      "metadata": {
        "id": "olssWjfukjCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set qs_id as index b\n",
        "train_df.set_index(\"qs_new\", drop = False, inplace = True, verify_integrity = True)\n",
        "test_df.set_index(\"qs_new\", drop = False, inplace = True, verify_integrity = True)\n",
        "val_df.set_index(\"qs_new\", drop = False, inplace = True, verify_integrity = True)"
      ],
      "metadata": {
        "id": "TSHWewDSlX7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the labels\n",
        "train_df['labels'] = label_encoder.fit_transform(train_df.labels)\n",
        "test_df['labels'] = label_encoder.fit_transform(test_df.labels)\n",
        "val_df['labels'] = label_encoder.fit_transform(val_df.labels)"
      ],
      "metadata": {
        "id": "hU1-ROZZl6iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(f'train_ft.csv')\n",
        "test_df = pd.read_csv(f'test_ft.csv')\n",
        "val_df = pd.read_csv(f'val_ft.csv')"
      ],
      "metadata": {
        "id": "_n0CL-IOnLeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up configuration with the hyperparameter ranges you want to check\n",
        "\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",  # grid, random\n",
        "    \"metric\": {\"name\": \"f1_eval\", \"goal\": \"maximize\"},# eval_loss?\n",
        "    \"parameters\": {\n",
        "        \"num_train_epochs\": {\"values\": [2]},\n",
        "        \"train_batch_size\":{\"values\":[8,16]},\n",
        "        \"learning_rate\": {\"min\": 1e-5, \"max\": 9e-4},\n",
        "        \"weight_decay\":{\"min\":0.0,\"max\":0.15},\n",
        "        'use_class_weights':{'values':[0,1]},\n",
        "        'stride':{'min':0.0, 'max':1.0},\n",
        "        'hidden_dropout_prob':{'min':0.1, 'max':0.3},\n",
        "        'attention_probs_dropout_prob':{'min':0.1, 'max':0.3}\n",
        "    },\n",
        "}\n"
      ],
      "metadata": {
        "id": "sO-DIWE1l8QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sweep -- need wandb API key\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"roberta_sweep\")\n"
      ],
      "metadata": {
        "id": "SZVVFkASmVeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "transformers_logger = logging.getLogger(\"transformers\")\n",
        "transformers_logger.setLevel(logging.WARNING)"
      ],
      "metadata": {
        "id": "wQfUHE5qmaD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = \"xlmroberta\"\n",
        "model_name = \"xlm-roberta-base\"\n",
        "\n",
        "model_args = ClassificationArgs()\n",
        "model_args.reprocess_input_data = True\n",
        "model_args.overwrite_output_dir = True\n",
        "model_args.evaluate_during_training = True\n",
        "evaluate_during_training_verbose=True\n",
        "model_args.manual_seed = 4\n",
        "model_args.num_train_epochs = 2\n",
        "model_args.use_multiprocessing = True\n",
        "model_args.learning_rate=1e-05\n",
        "model_args.train_batch_size = 8\n",
        "#model_args.eval_batch_size = 8\n",
        "model_args.max_seq_length=256\n",
        "model_args.labels_list = [0,1] # UPDATE\n",
        "model_args.sliding_window = True\n",
        "#model_args.stride = 0.6\n",
        "model_args.no_save = True\n",
        "#model_args.save_model_every_epoch=False\n",
        "model_args.save_optimizer_and_scheduler=False\n",
        "model_args.wandb_project = \"roberta_sweep\""
      ],
      "metadata": {
        "id": "x5GjHTVhmb3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init()\n",
        "\n",
        "    # Create a TransformerModel\n",
        "    model = ClassificationModel(\n",
        "        model_type,\n",
        "        model_name,\n",
        "        num_labels = 2,\n",
        "        weight = weights,\n",
        "        use_cuda=True,\n",
        "        args=model_args,\n",
        "        sweep_config=wandb.config,\n",
        "    )\n",
        "\n",
        "    # Train the model, specify metrics\n",
        "    model.train_model(train_df,\n",
        "                      eval_df=test_df,\n",
        "                      accuracy=accuracy_score,\n",
        "                      f1_train=f1_class)\n",
        "\n",
        "    # Evaluate the model\n",
        "    eval_res,_,_ = model.eval_model(val_df,\n",
        "                     accuracy_eval=accuracy_score,\n",
        "                     recall_eval=recall,\n",
        "                     precision_eval=precision,\n",
        "                     f1_eval=f1_class)\n",
        "\n",
        "    # add metrics to evaluate\n",
        "    wandb.log({'f1_eval':eval_res['f1_eval'],\n",
        "               'fp_eval':eval_res['fp'],\n",
        "               'fn_eval':eval_res['fn'],\n",
        "               'tn_eval':eval_res['tn'],\n",
        "               'tp_eval':eval_res['tp']\n",
        "               })\n",
        "\n",
        "    # Sync wandb\n",
        "    wandb.join()\n",
        "\n"
      ],
      "metadata": {
        "id": "5gLF33_emvnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train)"
      ],
      "metadata": {
        "id": "KsrgpD70m3LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above will send all the results to the respective wandb sweep page where you can view and export results to determine the highest values depending on what you want to see."
      ],
      "metadata": {
        "id": "Ajod4KQ0m87k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h4ot-_7Gm7jk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}