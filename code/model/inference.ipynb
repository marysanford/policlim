{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBHUYyhOU4bV"
      },
      "outputs": [],
      "source": [
        "!pip install simpletransformers transformers==4.40.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the required packages\n",
        "\n",
        "# Dataframes\n",
        "import pandas as pd, numpy as np\n",
        "\n",
        "# Regular expressions\n",
        "import re\n",
        "\n",
        "# Unidecoder\n",
        "import unicodedata\n",
        "\n",
        "# Timestamp / time measurment\n",
        "import time\n",
        "\n",
        "# for train/test data preparation\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Label encode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Model performance scores\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# PyTorch: enable GPU access\n",
        "import torch\n",
        "\n",
        "# Simpletransformers classifier\n",
        "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n"
      ],
      "metadata": {
        "id": "mXm6CTlUVcvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "gz3uSoiZVjkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "dat = pd.read_csv('training_data.csv')\n",
        "\n",
        "dat['final_climate']=dat['final_climate'].astype(int)\n",
        "dat['final_climate'].sum()"
      ],
      "metadata": {
        "id": "zn_GwKkoVc5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Â set qs_id as index\n",
        "dat.set_index(\"qs_new\", drop = False, inplace = True, verify_integrity = True)"
      ],
      "metadata": {
        "id": "vEI2BkSKVlYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make numeric labels\n",
        "dat[\"label\"] = dat[\"final_climate\"].astype(\"category\").cat.codes\n",
        "dat[\"label\"].value_counts()"
      ],
      "metadata": {
        "id": "YaToIVhjVdAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make stratifications of data by langauge and climate relevance, from https://stackoverflow.com/a/62918682\n",
        "dat[\"strata_\"] = dat.set_index(['language','label']).index.factorize()[0]"
      ],
      "metadata": {
        "id": "5Vha1UBaVdGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load GPU"
      ],
      "metadata": {
        "id": "i7SFIWFGVpgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to select a specific GPU, set it here:\n",
        "# gpu = 0\n",
        "# torch.cuda.set_device(gpu)\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use GPU {}:'.format(torch.cuda.current_device()), torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "Jj5AZ-BuVdNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up for training final model"
      ],
      "metadata": {
        "id": "uoiJfY4bVs-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the label encoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the labels\n",
        "dat['labels'] = label_encoder.fit_transform(train_df.label)\n"
      ],
      "metadata": {
        "id": "5F7V8NVdVsff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate weights\n",
        "weights = compute_class_weight(class_weight = 'balanced', classes=[0,1], y=dat.labels)\n",
        "weights = [*weights]\n",
        "print(weights)"
      ],
      "metadata": {
        "id": "0C6vCorRVdW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = \"xlmroberta\"\n",
        "model_name = \"xlm-roberta-base\""
      ],
      "metadata": {
        "id": "k-fw8fxYV8b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Create a ClassificationModel with optimised hyperparams\n",
        "model = ClassificationModel(model_type, model_name, weight=weights,\n",
        "                            num_labels = 2,\n",
        "                            args={'reprocess_input_data': True,\n",
        "                                  'overwrite_output_dir': True,\n",
        "                                  'output_dir': 'results_22May/',\n",
        "                                  # Hyperparameters\n",
        "                                  'train_batch_size': 8,\n",
        "                                  'num_train_epochs': 2,\n",
        "                                  'learning_rate': 1e-5,\n",
        "                                  'weight_decay': .187677,\n",
        "                                  'hidden_dropout_prob': .188775,\n",
        "                                  'attention_probs_dropout_prob': .330174,\n",
        "                                  # Text processing\n",
        "                                  'max_seq_length': 256,\n",
        "                                  'sliding_window': True,\n",
        "                                  'stride': 0.6,\n",
        "                                  'do_lower_case': True,\n",
        "                                  # Evaluation\n",
        "                                  'evaluate_during_training': False,\n",
        "                                  'evaluate_during_training_verbose': True,\n",
        "                                  'evaluate_during_training_steps': -1,\n",
        "                                  # Saving\n",
        "                                  'save_model_every_epoch': False,\n",
        "                                  'save_eval_checkpoints': True,\n",
        "                                  })\n",
        "\n"
      ],
      "metadata": {
        "id": "HePeFcBgWBDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Train and evaluate the model\n",
        "model.train_model(train_df = dat,\n",
        "                  f1_eval = f1_class)"
      ],
      "metadata": {
        "id": "_it0Ip_jWH0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Load model and collect predictions"
      ],
      "metadata": {
        "id": "bzc5f4fNW_Ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ClassificationModel(\n",
        "    model_type, model_name = 'results_22May'\n",
        ")"
      ],
      "metadata": {
        "id": "YhF6CFAGWH_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load full data\n",
        "master = pd.read_csv('total_predictions_training_15May_trimmed_for_pred.csv')"
      ],
      "metadata": {
        "id": "QcoPOv0fXDI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all training set dat['qs_new']\n",
        "master = master[~master['qs_new'].isin(dat['qs_new'])]\n",
        "master.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "NvGTZDRWWIFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "master.shape"
      ],
      "metadata": {
        "id": "Ty1OZeayXNaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Code for running (and saving) the predictions in batches in case GPU resources limited. Set variable stop to size of dataset or simply remove the row indexing  to do it all at once.\n",
        "start=0\n",
        "stop=int(2e5)\n",
        "preds,output = model.predict(master['original_text'][start:stop].tolist())\n",
        "pd.DataFrame(zip(master['qs_new'][start:stop],preds,output),columns=['qs_new','preds','output']).to_csv(f'results_22May/pred_outputs_{start}_{stop}.csv')\n"
      ],
      "metadata": {
        "id": "iz-618kuXeDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}